{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transliterate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CH5H34ck4TKJ",
        "outputId": "ef16c755-cac7-426a-dd6f-fa5b074c4ec5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transliterate\n",
            "  Downloading transliterate-1.10.2-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: six>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from transliterate) (1.17.0)\n",
            "Downloading transliterate-1.10.2-py2.py3-none-any.whl (45 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/45.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: transliterate\n",
            "Successfully installed transliterate-1.10.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chTTJ2LVVUVP"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import datetime\n",
        "import os\n",
        "import argparse\n",
        "from transliterate import translit\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DateType\n",
        "from pyspark.sql.functions import col, when, count"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Список из 25 имен\n",
        "prepared_list_names = [\n",
        "    \"Алексей\", \"Ольга\", \"Дмитрий\", \"Мария\", \"Иван\",\n",
        "    \"Анна\", \"Сергей\", \"Елена\", \"Андрей\", \"Наталья\",\n",
        "    \"Владимир\", \"Татьяна\", \"Михаил\", \"Светлана\", \"Кирилл\",\n",
        "    \"Юлия\", \"Александр\", \"Екатерина\", \"Николай\", \"Ирина\",\n",
        "    \"Василий\", \"Евгений\", \"Людмила\", \"Павел\", \"Роман\"\n",
        "]\n",
        "\n",
        "# Список из 40 городов\n",
        "prepared_list_cities = [\n",
        "    \"Москва\", \"Санкт-Петербург\", \"Новосибирск\", \"Екатеринбург\", \"Казань\",\n",
        "    \"Нижний Новгород\", \"Челябинск\", \"Самара\", \"Омск\", \"Ростов-на-Дону\",\n",
        "    \"Уфа\", \"Красноярск\", \"Воронеж\", \"Пермь\", \"Волгоград\",\n",
        "    \"Краснодар\", \"Тольятти\", \"Ижевск\", \"Ульяновск\", \"Барнаул\",\n",
        "    \"Тюмень\", \"Иркутск\", \"Саратов\", \"Хабаровск\", \"Ярославль\",\n",
        "    \"Владивосток\", \"Махачкала\", \"Томск\", \"Оренбург\", \"Кемерово\",\n",
        "    \"Новокузнецк\", \"Рязань\", \"Астрахань\", \"Пенза\", \"Липецк\",\n",
        "    \"Тула\", \"Киров\", \"Брянск\", \"Чебоксары\", \"Калининград\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "hd-dvSa5V9BY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "current_date = datetime.date.today()"
      ],
      "metadata": {
        "id": "yzEMufYyBqmh"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ф-ция генерации даты рождения\n",
        "def generate_birth_date(age: int) -> datetime.date:\n",
        "    # Расчет даты рождения для случайного возраста\n",
        "    random_date_of_birth = current_date - datetime.timedelta(days=age * 365)\n",
        "\n",
        "    return random_date_of_birth"
      ],
      "metadata": {
        "id": "bTg5P0019wam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ф-ция генерации даты регистрации.\n",
        "# Ограничения:\n",
        "# регистрация возможна после достижения человеком пяти лет и до текущей даты.\n",
        "def generate_registration_date(birth_date: datetime.date) -> datetime.date:\n",
        "    # toordinal() переводит дату в дни, а fromordinal() обратно в дату\n",
        "    start_date = birth_date.toordinal() + 5*365\n",
        "    end_date = current_date.toordinal()\n",
        "    random_registr_date = datetime.date \\\n",
        "        .fromordinal(random.randint(start_date, end_date))\n",
        "\n",
        "    return random_registr_date"
      ],
      "metadata": {
        "id": "fh_PkNMKrI8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ф-ции выбора случайного имени и города из отфильтрованного списка\n",
        "def random_name() -> str:\n",
        "  return random.choice([name for name in prepared_list_names if len(name) >= 5])\n",
        "\n",
        "def random_city() -> str:\n",
        "  return random.choice([city for city in prepared_list_cities if len(city) >= 7])"
      ],
      "metadata": {
        "id": "Zl90CT1RJBzi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ф-ция переименовывает .csv файлы в формат \"текущий год-месяц-день-dev.csv\" и\n",
        "# удаляет лишние файлы\n",
        "def rename_csv(output_path, date: datetime.date = current_date) -> str:\n",
        "    files_list = os.listdir(output_path)\n",
        "    new_filename = output_path + f'/{date}-dev.csv'\n",
        "\n",
        "    for file in files_list:\n",
        "        if file.startswith('part-') and file.endswith('.csv'):\n",
        "            old_name = output_path + '/' + file\n",
        "            os.rename(old_name, new_filename)\n",
        "        elif not file.endswith('dev.csv'):\n",
        "            os.remove(os.path.join(output_path, file))\n",
        "\n",
        "    return new_filename"
      ],
      "metadata": {
        "id": "WxhSFUOUcvpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ф-ция генерации данных\n",
        "def generate_data(num_rows: int) -> list[tuple]:\n",
        "    data = []\n",
        "\n",
        "    # Рассчитываем количество NULL значений (не более 5% в каждом столбце)\n",
        "    number_null_in_table = int(num_rows * 0.05)\n",
        "\n",
        "    # Для каждого столбца создаем свой счетчик\n",
        "    null_counts = {\n",
        "        'name': 0,\n",
        "        'email': 0,\n",
        "        'city': 0,\n",
        "        'age': 0,\n",
        "        'salary': 0,\n",
        "        'registration_date': 0\n",
        "    }\n",
        "\n",
        "    # Генерация данных\n",
        "    for i in range(0, num_rows):\n",
        "        name = random_name()\n",
        "        city = random_city()\n",
        "        age = random.randint(18, 95) # Генерация случайного возраста от 18 до 95 лет\n",
        "        birth_date = generate_birth_date(age)\n",
        "        registration_date = generate_registration_date(birth_date)\n",
        "        #во время преобразования символов из ru в en translit заменяет \"ь\" на \"'' (Ольга -> Ol'ga)\n",
        "        # с помощью .replace(\"'\", \"\") убираем \"'\" (Ольга -> Olga)\n",
        "        email = translit(name.lower(), 'ru', reversed=True).replace(\"'\", \"\")\\\n",
        "        + str(birth_date.year) + '_' + str(birth_date.day) + '@'\\\n",
        "        + random.choice(['ru', 'com'])\n",
        "        salary = random.choice(range(100, 500)) * 10**3\n",
        "\n",
        "        # промежуточная запись в словарь\n",
        "        dict_data ={\n",
        "            'name':name,\n",
        "            'city':city,\n",
        "            'age':age,\n",
        "            'registration_date':registration_date,\n",
        "            'email':email,\n",
        "            'salary':salary\n",
        "        }\n",
        "\n",
        "        # Проверяем для каждого ключа (столбца) условие для вставки NULL значений\n",
        "        for k, v in dict_data.items():\n",
        "            #1. счетчик для столбца <= допустимому кол-ву NULL значений по столбцу\n",
        "            #2. вероятность вставки NULL (если random.random() возвращает число меньше 0.05)\n",
        "            if null_counts[k] <= number_null_in_table and random.random() < 0.05:\n",
        "                dict_data[k] = None\n",
        "                null_counts[k] += 1  # Увеличиваем счетчик для этого столбца\n",
        "\n",
        "\n",
        "        # Создаем кортеж данных и добавляем его в итоговый список\n",
        "        row_data = (i + 1, dict_data['name'], dict_data['email'], dict_data['city'],\\\n",
        "                    dict_data['age'], dict_data['salary'], dict_data['registration_date'])\n",
        "\n",
        "        data.append(row_data)\n",
        "\n",
        "    return data\n",
        "\n"
      ],
      "metadata": {
        "id": "eruc-b2hB-p8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ф-ция создания 'DataFrame'\n",
        "def create_df(spark: SparkSession, schema: StructType, data: list[tuple]) -> 'DataFrame':\n",
        "\n",
        "    df = spark.createDataFrame(data=data, schema=schema)\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "Bl0476NwwxR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ф-ция проверки условия наличия NULL значений в данных\n",
        "def check_null_value(df: 'DataFrame', count_data: int, columns_list: list) -> None:\n",
        "    # ф-ция проверки условия на превышение NULL значений по столбцам (не прывышать 5% в каждом из столбцов)\n",
        "    def check_null_percentage(column_name: str, cnt_null_colum: int, count_data: int) -> None:\n",
        "        null_percentage = (cnt_null_colum / count_data) * 100\n",
        "        if null_percentage > 5 and null_percentage <= 6:\n",
        "            print(f'количество NULL в столбце \"{column_name}\" незначительно превышает 5% и равна {null_percentage:.2f}%')\n",
        "        elif null_percentage > 6:\n",
        "            print(f'количество NULL в столбце \"{column_name}\" ЗНАЧИТЕЛЬНО превышает 5% и равна {null_percentage:.2f}%')\n",
        "        else:\n",
        "            print(f'количество NULL в столбце \"{column_name}\" не превышает 5% и равна {null_percentage:.2f}%')\n",
        "\n",
        "    for colum in columns_list:\n",
        "        # количество NULL значений по столбцам\n",
        "        cnt_null_colum = df.filter(col(colum).isNull()).count()\n",
        "        check_null_percentage(colum, cnt_null_colum, count_data)\n"
      ],
      "metadata": {
        "id": "H0-pkspIxgFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ф-ция записи данных в .csv\n",
        "def data_in_csv(df: 'DataFrame', report_date: datetime.date, output_path: str, count_data: int) -> None:\n",
        "\n",
        "    df.coalesce(1).write.csv(output_path, header=True, mode=\"append\")\n",
        "    filename = rename_csv(output_path, report_date)\n",
        "\n",
        "    print(f'Было сгенерировано {count_data} строк данных, \\\n",
        "которые были записаны в файл \\'{filename}\\' за дату {report_date}')"
      ],
      "metadata": {
        "id": "ObK0cpfByZlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "    current_date = datetime.date.today()\n",
        "\n",
        "    spark = SparkSession.builder \\\n",
        "        .appName(\"generator_csv\") \\\n",
        "        .config(\"spark.master\", \"local[*]\") \\\n",
        "        .getOrCreate()\n",
        "\n",
        "    schema = StructType([\n",
        "        StructField('id', IntegerType(), False),\n",
        "        StructField('name', StringType()),\n",
        "        StructField('email', StringType()),\n",
        "        StructField('city', StringType()),\n",
        "        StructField('age', IntegerType()),\n",
        "        StructField('salary', IntegerType()),\n",
        "        StructField('registration_date', DateType())\n",
        "    ])\n",
        "\n",
        "    # вариант 1 ввода числа строк, дней и путь к директории с помощью input\n",
        "    #    num_rows = int(input('Введите число генерируемых данных (количество строк): '))\n",
        "    #    cnt_day = int(input('Введите количество дней, за которые нужно сгенерировать данные: '))\n",
        "    #    output_path = input('Введите путь к директории для создания .csv файлов: ')  # '/content/sample_data'\n",
        "\n",
        "\n",
        "    # вариант 2 с использованием библиотеки argparse, через аргумент\n",
        "    # создаем парсер\n",
        "    parser = argparse.ArgumentParser(description=\"Генерация синтетических данных.\")\n",
        "    # добавляем аргументы\n",
        "    parser.add_argument('-r', '--rows', help='Число генерируемых данных (количество строк)',\n",
        "                        nargs='?', type=int, default=100)\n",
        "    parser.add_argument('-d', '--days', help='Число дней, за которые нужно сгенерировать данные',\n",
        "                    nargs='?', type=int, default=5)\n",
        "    parser.add_argument('--dir', help='путь к директории для сохранения .csv файлов',\n",
        "                    nargs='?', type=str, default='/content/sample_data')\n",
        "\n",
        "    # Разбор аргументов, игнорируя незнакомые(так как colab передает свои аргументы и будет ошибка)\n",
        "    args, unknown = parser.parse_known_args()\n",
        "\n",
        "    # Получаем значение из аргумента rows и days (если они был передан), либо используем дефолтное значение\n",
        "    num_rows = args.rows\n",
        "    cnt_day = args.days\n",
        "    output_path = args.dir\n",
        "\n",
        "    for days_ago in range(cnt_day):\n",
        "        report_date = current_date - datetime.timedelta(days=days_ago)\n",
        "        if report_date.day  % 2 != 0:\n",
        "            data = generate_data(num_rows)\n",
        "            df = create_df(spark, schema, data)\n",
        "            columns_list = df.columns\n",
        "            count_data = df.count()\n",
        "            data_in_csv(df, report_date, output_path, count_data)\n",
        "            #check_null_value(df, count_data, columns_list)\n",
        "\n",
        "\n",
        "    spark.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3f3-4vZvjcD",
        "outputId": "bd4bad19-8955-4d78-85c8-1b0bc72d2069"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Было сгенерировано 100 строк данных, которые были записаны в файл '/content/sample_data/2025-02-21-dev.csv' за дату 2025-02-21\n",
            "Было сгенерировано 100 строк данных, которые были записаны в файл '/content/sample_data/2025-02-19-dev.csv' за дату 2025-02-19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "############ весь код ниже"
      ],
      "metadata": {
        "id": "Adk3ZUe23f2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import datetime\n",
        "import os\n",
        "import argparse\n",
        "from transliterate import translit\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DateType\n",
        "from pyspark.sql.functions import col, when, count\n",
        "\n",
        "# Список из 25 имен\n",
        "prepared_list_names = [\n",
        "    \"Алексей\", \"Ольга\", \"Дмитрий\", \"Мария\", \"Иван\",\n",
        "    \"Анна\", \"Сергей\", \"Елена\", \"Андрей\", \"Наталья\",\n",
        "    \"Владимир\", \"Татьяна\", \"Михаил\", \"Светлана\", \"Кирилл\",\n",
        "    \"Юлия\", \"Александр\", \"Екатерина\", \"Николай\", \"Ирина\",\n",
        "    \"Василий\", \"Евгений\", \"Людмила\", \"Павел\", \"Роман\"\n",
        "]\n",
        "\n",
        "# Список из 40 городов\n",
        "prepared_list_cities = [\n",
        "    \"Москва\", \"Санкт-Петербург\", \"Новосибирск\", \"Екатеринбург\", \"Казань\",\n",
        "    \"Нижний Новгород\", \"Челябинск\", \"Самара\", \"Омск\", \"Ростов-на-Дону\",\n",
        "    \"Уфа\", \"Красноярск\", \"Воронеж\", \"Пермь\", \"Волгоград\",\n",
        "    \"Краснодар\", \"Тольятти\", \"Ижевск\", \"Ульяновск\", \"Барнаул\",\n",
        "    \"Тюмень\", \"Иркутск\", \"Саратов\", \"Хабаровск\", \"Ярославль\",\n",
        "    \"Владивосток\", \"Махачкала\", \"Томск\", \"Оренбург\", \"Кемерово\",\n",
        "    \"Новокузнецк\", \"Рязань\", \"Астрахань\", \"Пенза\", \"Липецк\",\n",
        "    \"Тула\", \"Киров\", \"Брянск\", \"Чебоксары\", \"Калининград\"\n",
        "]\n",
        "\n",
        "current_date = datetime.date.today()\n",
        "\n",
        "# ф-ция генерации даты рождения\n",
        "def generate_birth_date(age: int) -> datetime.date:\n",
        "    # Расчет даты рождения для случайного возраста\n",
        "    random_date_of_birth = current_date - datetime.timedelta(days=age * 365)\n",
        "\n",
        "    return random_date_of_birth\n",
        "\n",
        "\n",
        "# ф-ция генерации даты регистрации.\n",
        "# Ограничения:\n",
        "# регистрация возможна после достижения человеком пяти лет и до текущей даты.\n",
        "def generate_registration_date(birth_date: datetime.date) -> datetime.date:\n",
        "    # toordinal() переводит дату в дни, а fromordinal() обратно в дату\n",
        "    start_date = birth_date.toordinal() + 5*365\n",
        "    end_date = current_date.toordinal()\n",
        "    random_registr_date = datetime.date \\\n",
        "        .fromordinal(random.randint(start_date, end_date))\n",
        "\n",
        "    return random_registr_date\n",
        "\n",
        "# ф-ции выбора случайного имени и города из отфильтрованного списка\n",
        "def random_name() -> str:\n",
        "  return random.choice([name for name in prepared_list_names if len(name) >= 5])\n",
        "\n",
        "def random_city() -> str:\n",
        "  return random.choice([city for city in prepared_list_cities if len(city) >= 7])\n",
        "\n",
        "# ф-ция переименовывает .csv файлы в формат \"текущий год-месяц-день-dev.csv\" и\n",
        "# удаляет лишние файлы\n",
        "def rename_csv(output_path, date: datetime.date = current_date) -> str:\n",
        "    files_list = os.listdir(output_path)\n",
        "    new_filename = output_path + f'/{date}-dev.csv'\n",
        "\n",
        "    for file in files_list:\n",
        "        if file.startswith('part-') and file.endswith('.csv'):\n",
        "            old_name = output_path + '/' + file\n",
        "            os.rename(old_name, new_filename)\n",
        "        elif not file.endswith('dev.csv'):\n",
        "            os.remove(os.path.join(output_path, file))\n",
        "\n",
        "    return new_filename\n",
        "\n",
        "# ф-ция генерации данных\n",
        "def generate_data(num_rows: int) -> list[tuple]:\n",
        "    data = []\n",
        "\n",
        "    # Рассчитываем количество NULL значений (не более 5% в каждом столбце)\n",
        "    number_null_in_table = int(num_rows * 0.05)\n",
        "\n",
        "    # Для каждого столбца создаем свой счетчик\n",
        "    null_counts = {\n",
        "        'name': 0,\n",
        "        'email': 0,\n",
        "        'city': 0,\n",
        "        'age': 0,\n",
        "        'salary': 0,\n",
        "        'registration_date': 0\n",
        "    }\n",
        "\n",
        "    # Генерация данных\n",
        "    for i in range(0, num_rows):\n",
        "        name = random_name()\n",
        "        city = random_city()\n",
        "        age = random.randint(18, 95) # Генерация случайного возраста от 18 до 95 лет\n",
        "        birth_date = generate_birth_date(age)\n",
        "        registration_date = generate_registration_date(birth_date)\n",
        "        #во время преобразования символов из ru в en translit заменяет \"ь\" на \"'' (Ольга -> Ol'ga)\n",
        "        # с помощью .replace(\"'\", \"\") убираем \"'\" (Ольга -> Olga)\n",
        "        email = translit(name.lower(), 'ru', reversed=True).replace(\"'\", \"\")\\\n",
        "        + str(birth_date.year) + '_' + str(birth_date.day) + '@'\\\n",
        "        + random.choice(['ru', 'com'])\n",
        "        salary = random.choice(range(100, 500)) * 10**3\n",
        "\n",
        "        # промежуточная запись в словарь\n",
        "        dict_data ={\n",
        "            'name':name,\n",
        "            'city':city,\n",
        "            'age':age,\n",
        "            'registration_date':registration_date,\n",
        "            'email':email,\n",
        "            'salary':salary\n",
        "        }\n",
        "\n",
        "        # Проверяем для каждого ключа (столбца) условие для вставки NULL значений\n",
        "        for k, v in dict_data.items():\n",
        "            #1. счетчик для столбца <= допустимому кол-ву NULL значений по столбцу\n",
        "            #2. вероятность вставки NULL (если random.random() возвращает число меньше 0.05)\n",
        "            if null_counts[k] <= number_null_in_table and random.random() < 0.05:\n",
        "                dict_data[k] = None\n",
        "                null_counts[k] += 1  # Увеличиваем счетчик для этого столбца\n",
        "\n",
        "\n",
        "        # Создаем кортеж данных и добавляем его в итоговый список\n",
        "        row_data = (i + 1, dict_data['name'], dict_data['email'], dict_data['city'],\\\n",
        "                    dict_data['age'], dict_data['salary'], dict_data['registration_date'])\n",
        "\n",
        "        data.append(row_data)\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "\n",
        "# ф-ция создания 'DataFrame'\n",
        "def create_df(spark: SparkSession, schema: StructType, data: list[tuple]) -> 'DataFrame':\n",
        "\n",
        "    df = spark.createDataFrame(data=data, schema=schema)\n",
        "\n",
        "    return df\n",
        "\n",
        "# ф-ция проверки условия наличия NULL значений в данных\n",
        "def check_null_value(df: 'DataFrame', count_data: int, columns_list: list) -> None:\n",
        "    # ф-ция проверки условия на превышение NULL значений по столбцам (не прывышать 5% в каждом из столбцов)\n",
        "    def check_null_percentage(column_name: str, cnt_null_colum: int, count_data: int) -> None:\n",
        "        null_percentage = (cnt_null_colum / count_data) * 100\n",
        "        if null_percentage > 5 and null_percentage <= 6:\n",
        "            print(f'количество NULL в столбце \"{column_name}\" незначительно превышает 5% и равна {null_percentage:.2f}%')\n",
        "        elif null_percentage > 6:\n",
        "            print(f'количество NULL в столбце \"{column_name}\" ЗНАЧИТЕЛЬНО превышает 5% и равна {null_percentage:.2f}%')\n",
        "        else:\n",
        "            print(f'количество NULL в столбце \"{column_name}\" не превышает 5% и равна {null_percentage:.2f}%')\n",
        "\n",
        "    for colum in columns_list:\n",
        "        # количество NULL значений по столбцам\n",
        "        cnt_null_colum = df.filter(col(colum).isNull()).count()\n",
        "        check_null_percentage(colum, cnt_null_colum, count_data)\n",
        "\n",
        "\n",
        "# ф-ция записи данных в .csv\n",
        "def data_in_csv(df: 'DataFrame', report_date: datetime.date, output_path: str, count_data: int) -> None:\n",
        "\n",
        "    df.coalesce(1).write.csv(output_path, header=True, mode=\"append\")\n",
        "    filename = rename_csv(output_path, report_date)\n",
        "\n",
        "\n",
        "    print(f'Было сгенерировано {count_data} строк данных, \\\n",
        "которые были записаны в файл \\'{filename}\\' за дату {report_date}')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    spark = SparkSession.builder \\\n",
        "        .appName(\"generator_csv\") \\\n",
        "        .config(\"spark.master\", \"local[*]\") \\\n",
        "        .getOrCreate()\n",
        "\n",
        "    schema = StructType([\n",
        "        StructField('id', IntegerType(), False),\n",
        "        StructField('name', StringType()),\n",
        "        StructField('email', StringType()),\n",
        "        StructField('city', StringType()),\n",
        "        StructField('age', IntegerType()),\n",
        "        StructField('salary', IntegerType()),\n",
        "        StructField('registration_date', DateType())\n",
        "    ])\n",
        "\n",
        "    # вариант 1 ввода числа строк, дней и путь к директории с помощью input\n",
        "    #    num_rows = int(input('Введите число генерируемых данных (количество строк): '))\n",
        "    #    cnt_day = int(input('Введите количество дней, за которые нужно сгенерировать данные: '))\n",
        "    #    output_path = input('Введите путь к директории для создания .csv файлов: ')  # '/content/sample_data'\n",
        "\n",
        "\n",
        "    # вариант 2 с использованием библиотеки argparse, через аргумент\n",
        "    # создаем парсер\n",
        "    parser = argparse.ArgumentParser(description=\"Генерация синтетических данных.\")\n",
        "    # добавляем аргументы\n",
        "    parser.add_argument('-r', '--rows', help='Число генерируемых данных (количество строк)',\n",
        "                        nargs='?', type=int, default=100)\n",
        "    parser.add_argument('-d', '--days', help='Число дней, за которые нужно сгенерировать данные',\n",
        "                    nargs='?', type=int, default=5)\n",
        "    parser.add_argument('--dir', help='путь к директории для сохранения .csv файлов',\n",
        "                    nargs='?', type=str, default='/content/sample_data')\n",
        "\n",
        "    # Разбор аргументов, игнорируя незнакомые(так как colab передает свои аргументы и будет ошибка)\n",
        "    args, unknown = parser.parse_known_args()\n",
        "\n",
        "    # Получаем значение из аргумента rows и days (если они был передан), либо используем дефолтное значение\n",
        "    num_rows = args.rows\n",
        "    cnt_day = args.days\n",
        "    output_path = args.dir\n",
        "\n",
        "    for days_ago in range(cnt_day):\n",
        "        report_date = current_date - datetime.timedelta(days=days_ago)\n",
        "        if report_date.day  % 2 != 0:\n",
        "            data = generate_data(num_rows)\n",
        "            df = create_df(spark, schema, data)\n",
        "            columns_list = df.columns\n",
        "            count_data = df.count()\n",
        "            data_in_csv(df, report_date, output_path, count_data)\n",
        "            #check_null_value(df, count_data, columns_list)\n",
        "\n",
        "\n",
        "    spark.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUSl94X86-LE",
        "outputId": "f7351f9c-85e3-4295-b712-62112005006c"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Было сгенерировано 100 строк данных, которые были записаны в файл '/content/sample_data/2025-02-21-dev.csv' за дату 2025-02-21\n",
            "Было сгенерировано 100 строк данных, которые были записаны в файл '/content/sample_data/2025-02-19-dev.csv' за дату 2025-02-19\n"
          ]
        }
      ]
    }
  ]
}